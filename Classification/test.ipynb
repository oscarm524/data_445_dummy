{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea206712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.3 MB 17 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 63.7 MB/s eta 0:00:01     |███████████████████████████▎    | 4.7 MB 63.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.40.0-cp36-cp36m-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 38.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.14.0-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 79.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 66.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 60.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 69.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 79.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 41.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 78.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 81.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.0)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=896a4e954814d56a31c49c88518ffbb48b05bf9cba3b64cf94d886c4d044f73a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=e71b80be0cfdab7cbf9d086025bd0a7e16aedc2a89e36d7af55b7978aa84ae6d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "Successfully installed absl-py-0.14.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.40.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43eaff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "\n",
    "## Defining the bucket \n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-445'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file \n",
    "file_key = 'Fall_2021/In_Class_Assignments/framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Reading the csv file\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "heart = heart.dropna()\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161be80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the input and target variables\n",
    "X = heart[['age', 'currentSmoker', 'totChol', 'BMI', 'heartRate']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "## Splitting the data \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59788976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming the input variables\n",
    "scaler_train = MinMaxScaler(feature_range = (0, 1)).fit(X_train)\n",
    "X_train = scaler_train.transform(X_train)\n",
    "\n",
    "scaler_test = MinMaxScaler(feature_range = (0, 1)).fit(X_test)\n",
    "X_test = scaler_train.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bcd1de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e69911588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'tanh'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "mlp1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "## Building the model\n",
    "mlp1.fit(X_train, tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "         epochs = 100,\n",
    "         batch_size = 500, \n",
    "         validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)), \n",
    "         verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d20814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e698489e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "mlp2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "## Building the model\n",
    "mlp2.fit(X_train, tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "         epochs = 100,\n",
    "         batch_size = 500, \n",
    "         validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)),\n",
    "         verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eedae620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.391304347826087"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extracting predictions\n",
    "mlp_pred1 = mlp1.predict(X_test)[:, 1]\n",
    "\n",
    "## Changing likelihood to labels\n",
    "mlp_pred1 = np.where(mlp_pred1 < 0.15, 0, 1)\n",
    "\n",
    "## Computing the recall\n",
    "recall_score(Y_test, mlp_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff5d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739130434782609"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extracting predictions\n",
    "mlp_pred2 = mlp2.predict(X_test)[:, 1]\n",
    "\n",
    "## Changing likelihood to labels\n",
    "mlp_pred2 = np.where(mlp_pred2 < 0.15, 0, 1)\n",
    "\n",
    "## Computing the recall\n",
    "recall_score(Y_test, mlp_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e1029",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "098261a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521739130434783"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the svm model\n",
    "svm_md1 = SVC(kernel = 'rbf', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "## Predicting on the test dataset\n",
    "svm_pred1 = svm_md1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Changing likelihood to labels\n",
    "svm_pred1 = np.where(svm_pred1 < 0.15, 0, 1)\n",
    "\n",
    "## Computing the recall\n",
    "recall_score(Y_test, svm_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7adfd713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7304347826086957"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Building the svm model\n",
    "svm_md2 = SVC(kernel = 'poly', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "## Predicting on the test dataset\n",
    "svm_pred2 = svm_md2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Changing likelihood to labels\n",
    "svm_pred2 = np.where(svm_pred2 < 0.15, 0, 1)\n",
    "\n",
    "## Computing the recall\n",
    "recall_score(Y_test, svm_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "994764b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'md1_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-62165d1631b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmlp_pred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmlp_pred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_pred1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmd1_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_pred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'md1_results' is not defined"
     ]
    }
   ],
   "source": [
    "## Defining lists to store results\n",
    "md1_recall = list()\n",
    "md2_recall = list()\n",
    "md3_recall = list()\n",
    "md4_recall = list()\n",
    "\n",
    "for i in range(0, 100):\n",
    "    print(i)\n",
    "    ## Splitting the data \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "    \n",
    "    ## Transforming the input variables\n",
    "    scaler_train = MinMaxScaler(feature_range = (0, 1)).fit(X_train)\n",
    "    X_train = scaler_train.transform(X_train)\n",
    "\n",
    "    scaler_test = MinMaxScaler(feature_range = (0, 1)).fit(X_test)\n",
    "    X_test = scaler_train.transform(X_test)\n",
    "    \n",
    "    #############\n",
    "    ## Model 1 ##\n",
    "    #############\n",
    "    \n",
    "    mlp1 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'tanh'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    mlp1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    mlp1.fit(X_train, tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "             epochs = 100,\n",
    "             batch_size = 500, \n",
    "             validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)), \n",
    "             verbose = 0)\n",
    "    \n",
    "    mlp_pred1 = mlp1.predict(X_test)[:, 1]\n",
    "    mlp_pred1 = np.where(mlp_pred1 < 0.15, 0, 1)\n",
    "    md1_recall.append(recall_score(Y_test, mlp_pred1))\n",
    "    \n",
    "    #############\n",
    "    ## Model 2 ##\n",
    "    #############\n",
    "    \n",
    "    mlp2 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    mlp2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    mlp2.fit(X_train, tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "             epochs = 100,\n",
    "             batch_size = 500, \n",
    "             validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)),\n",
    "             verbose = 0)\n",
    "    \n",
    "    mlp_pred2 = mlp2.predict(X_test)[:, 1]\n",
    "    mlp_pred2 = np.where(mlp_pred2 < 0.15, 0, 1)\n",
    "    md2_recall.append(recall_score(Y_test, mlp_pred2))\n",
    "    \n",
    "    #############\n",
    "    ## Model 3 ##\n",
    "    #############\n",
    "    \n",
    "    svm_md1 = SVC(kernel = 'rbf', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "    svm_pred1 = svm_md1.predict_proba(X_test)[:, 1]\n",
    "    svm_pred1 = np.where(svm_pred1 < 0.15, 0, 1)\n",
    "    md3_recall.append(recall_score(Y_test, svm_pred1))\n",
    "    \n",
    "    #############\n",
    "    ## Model 4 ##\n",
    "    #############\n",
    "    \n",
    "    svm_md2 = SVC(kernel = 'poly', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "    svm_pred2 = svm_md2.predict_proba(X_test)[:, 1]\n",
    "    svm_pred2 = np.where(svm_pred2 < 0.15, 0, 1)\n",
    "    md4_recall.append(recall_score(Y_test, svm_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
