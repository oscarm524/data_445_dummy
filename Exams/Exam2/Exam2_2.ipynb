{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d382d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "## Defining the bucket \n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-445'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file \n",
    "file_key_1 = 'Demos/churn-bigml-80.csv'\n",
    "file_key_2 = 'Demos/churn-bigml-20.csv'\n",
    "\n",
    "bucket_object_1 = bucket.Object(file_key_1)\n",
    "file_object_1 = bucket_object_1.get()\n",
    "file_content_stream_1 = file_object_1.get('Body')\n",
    "\n",
    "bucket_object_2 = bucket.Object(file_key_2)\n",
    "file_object_2 = bucket_object_2.get()\n",
    "file_content_stream_2 = file_object_2.get('Body')\n",
    "\n",
    "## Reading the csv files\n",
    "telecom_train = pd.read_csv(file_content_stream_1)\n",
    "telecom_test = pd.read_csv(file_content_stream_2)\n",
    "\n",
    "## Changing logical value to numbers\n",
    "telecom_train['Churn_numb'] = np.where(telecom_train['Churn'] == False, 0, 1)\n",
    "telecom_test['Churn_numb'] = np.where(telecom_test['Churn'] == False, 0, 1)\n",
    "\n",
    "telecom_train['International_plan'] = np.where(telecom_train['International_plan'] == 'No', 0, 1)\n",
    "telecom_test['International_plan'] = np.where(telecom_test['International_plan'] == 'No', 0, 1)\n",
    "\n",
    "telecom_train['Voice_mail_plan'] = np.where(telecom_train['Voice_mail_plan'] == 'No', 0, 1)\n",
    "telecom_test['Voice_mail_plan'] = np.where(telecom_test['Voice_mail_plan'] == 'No', 0, 1)\n",
    "\n",
    "telecom_train['total_charge'] = telecom_train['Total_day_charge'] + telecom_train['Total_eve_charge'] + telecom_train['Total_night_charge'] + telecom_train['Total_intl_charge']\n",
    "telecom_test['total_charge'] = telecom_test['Total_day_charge'] + telecom_test['Total_eve_charge'] + telecom_test['Total_night_charge'] + telecom_test['Total_intl_charge']\n",
    "\n",
    "## Selecting variables of interest\n",
    "telecom_train = telecom_train[['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls', 'Churn_numb']]\n",
    "telecom_test = telecom_test[['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls', 'Churn_numb']]\n",
    "\n",
    "## Defining the input and target variables\n",
    "X = telecom_train[['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']]\n",
    "Y = telecom_train['Churn_numb']\n",
    "\n",
    "## Defining data-frame to store results \n",
    "RF_importances = pd.DataFrame({'Account_length': np.repeat(np.nan, 100), 'International_plan': np.repeat(np.nan, 100), 'Voice_mail_plan': np.repeat(np.nan, 100), 'total_charge': np.repeat(np.nan, 100), 'Customer_service_calls': np.repeat(np.nan, 100)})\n",
    "Ada_importances = pd.DataFrame({'Account_length': np.repeat(np.nan, 100), 'International_plan': np.repeat(np.nan, 100), 'Voice_mail_plan': np.repeat(np.nan, 100), 'total_charge': np.repeat(np.nan, 100), 'Customer_service_calls': np.repeat(np.nan, 100)})\n",
    "GB_importances = pd.DataFrame({'Account_length': np.repeat(np.nan, 100), 'International_plan': np.repeat(np.nan, 100), 'Voice_mail_plan': np.repeat(np.nan, 100), 'total_charge': np.repeat(np.nan, 100), 'Customer_service_calls': np.repeat(np.nan, 100)})\n",
    "\n",
    "for i in range(0, 100):\n",
    "\n",
    "    ## Splitting the data \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    ###################\n",
    "    ## Random Forest ##\n",
    "    ###################\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    RF_importances.loc[i] = RF.feature_importances_\n",
    "    \n",
    "    ##############\n",
    "    ## AdaBoost ##\n",
    "    ##############\n",
    "    \n",
    "    Ada = AdaBoostClassifier(n_estimators = 500, base_estimator = DecisionTreeClassifier(max_depth = 3), learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    Ada_importances.loc[i] = Ada.feature_importances_\n",
    "    \n",
    "    #######################\n",
    "    ## Gradient Boosting ##\n",
    "    #######################\n",
    "    \n",
    "    GB = GradientBoostingClassifier(n_estimators = 500, max_depth = 3, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    GB_importances.loc[i] = GB.feature_importances_\n",
    "    \n",
    "## Combining the importances of the three models \n",
    "Feature_Importances = pd.concat([RF_importances, Ada_importances, GB_importances], axis = 0)\n",
    "Feature_Importances.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df4b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-defining the input and target variables\n",
    "X = telecom_train[['Account_length', 'International_plan', 'total_charge', 'Customer_service_calls']]\n",
    "Y = telecom_train['Churn_numb']\n",
    "\n",
    "def expand_grid(model):\n",
    "    \n",
    "    if (model == 'RF'):\n",
    "        \n",
    "        dictionary = {'n_tree': [100, 500, 1000, 1500, 2000],\n",
    "                      'depth': [3, 5, 7]}\n",
    "        \n",
    "        param = pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "        param['accuracy'] = np.nan\n",
    "        param['recall'] = np.nan\n",
    "    \n",
    "        return param\n",
    "    \n",
    "    elif ((model == 'Ada') | (model == 'GB')):\n",
    "        \n",
    "        dictionary = {'n_tree': [100, 500, 1000, 1500, 2000],\n",
    "                      'depth': [3, 5, 7],\n",
    "                      'learning_rate': [0.1, 0.01, 0.001]}\n",
    "    \n",
    "        param = pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "        param['accuracy'] = np.nan\n",
    "        param['recall'] = np.nan\n",
    "    \n",
    "        return param\n",
    "        \n",
    "\n",
    "def one_round(X_train, X_test, Y_train, Y_test, model):\n",
    "    \n",
    "    if (model == 'RF'):\n",
    "        \n",
    "        ## Defining the grid of hyper-parameters\n",
    "        RF_param = expand_grid('RF')\n",
    "\n",
    "        for i in range(0, RF_param.shape[0]):\n",
    "\n",
    "            ## Building the model\n",
    "            RF = RandomForestClassifier(n_estimators = RF_param['n_tree'][i], max_depth = RF_param['depth'][i]).fit(X_train, Y_train)\n",
    "\n",
    "            ## Predicting on test\n",
    "            RF_pred = RF.predict_proba(X_test)[:, 1]\n",
    "            RF_pred = np.where(RF_pred < 0.1, 0, 1)\n",
    "\n",
    "            ## Computing & storing accuracy and recall \n",
    "            RF_param.loc[i, 'accuracy'] = accuracy_score(Y_test, RF_pred)\n",
    "            RF_param.loc[i, 'recall'] = recall_score(Y_test, RF_pred)\n",
    "\n",
    "        return RF_param\n",
    "    \n",
    "    elif (model == 'Ada'):\n",
    "        \n",
    "        ## Defining the grid of hyper-parameters\n",
    "        Ada_param = expand_grid('Ada')\n",
    "        \n",
    "        for i in range(0, Ada_param.shape[0]):\n",
    "\n",
    "            ## Building the model\n",
    "            Ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = Ada_param['depth'][i]), n_estimators = Ada_param['n_tree'][i], learning_rate = Ada_param['learning_rate'][i]).fit(X_train, Y_train)\n",
    "\n",
    "            ## Predicting on test\n",
    "            Ada_pred = Ada.predict_proba(X_test)[:, 1]\n",
    "            Ada_pred = np.where(Ada_pred < 0.1, 0, 1)\n",
    "\n",
    "            ## Computing & storing accuracy and recall \n",
    "            Ada_param.loc[i, 'accuracy'] = accuracy_score(Y_test, Ada_pred)\n",
    "            Ada_param.loc[i, 'recall'] = recall_score(Y_test, Ada_pred)\n",
    "\n",
    "        return Ada_param\n",
    "    \n",
    "    elif (model == 'GB'):\n",
    "        \n",
    "        ## Defining the grid of hyper-parameters\n",
    "        GB_param = expand_grid('GB')\n",
    "        \n",
    "        for i in range(0, GB_param.shape[0]):\n",
    "            \n",
    "            ## Building the model \n",
    "            GB = GradientBoostingClassifier(n_estimators = GB_param['n_tree'][i], max_depth = GB_param['depth'][i], learning_rate = GB_param['learning_rate'][i]).fit(X_train, Y_train)\n",
    "        \n",
    "            ## Predicting on test \n",
    "            GB_pred = GB.predict_proba(X_test)[:, 1]\n",
    "            GB_pred = np.where(GB_pred < 0.1, 0, 1)\n",
    "            \n",
    "            ## Computing & storing accuracy and recall \n",
    "            GB_param.loc[i, 'accuracy'] = accuracy_score(Y_test, GB_pred)\n",
    "            GB_param.loc[i, 'recall'] = recall_score(Y_test, GB_pred)\n",
    "            \n",
    "        return GB_param\n",
    "    \n",
    "    \n",
    "def multiple_rounds(X, Y, numb_rounds, model):\n",
    "    \n",
    "    ## Defining list to store results\n",
    "    results = list()\n",
    "    \n",
    "    for i in range(0, numb_rounds):\n",
    "        \n",
    "        ## Splitting data \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "        \n",
    "        if (model == 'RF'):\n",
    "            \n",
    "            ## Storing results\n",
    "            results.append(one_round(X_train, X_test, Y_train, Y_test, 'RF'))\n",
    "            \n",
    "        elif (model == 'Ada'):\n",
    "            \n",
    "            ## Storing results \n",
    "            results.append(one_round(X_train, X_test, Y_train, Y_test, 'Ada'))\n",
    "        \n",
    "        elif (model == 'GB'):\n",
    "            \n",
    "            ## Storing results\n",
    "            results.append(one_round(X_train, X_test, Y_train, Y_test, 'GB'))\n",
    "    \n",
    "    ## Putting all the results together \n",
    "    results = pd.concat(results)\n",
    "    \n",
    "    if (model == 'RF'):\n",
    "    \n",
    "        results = results.groupby(['n_tree', 'depth']).agg({'accuracy': 'mean', 'recall': 'mean'})\n",
    "        results = results.sort_values(by = ['accuracy', 'recall'], ascending = False)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        results = results.groupby(['n_tree', 'depth', 'learning_rate']).agg({'accuracy': 'mean', 'recall': 'mean'})\n",
    "        results = results.sort_values(by = ['accuracy', 'recall'], ascending = False)\n",
    "        \n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
